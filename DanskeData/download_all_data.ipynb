{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for downloading all data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "#import urllib.request\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import datetime as dt\n",
    "# import pycountry as pc\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for whether all data should be updated, or only recent\n",
    "downloadAllData = False\n",
    "downloadAllData = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make folders if they aren't already there\n",
    "os.system(\"mkdir ssi_dashboard_zipped\")\n",
    "os.system(\"mkdir ssi_dashboard\")\n",
    "os.system(\"mkdir ssi_vacc_zipped\")\n",
    "os.system(\"mkdir ssi_vacc\")\n",
    "os.system(\"mkdir ssi_data_zipped\")\n",
    "os.system(\"mkdir ssi_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "ssidatapath = \"ssi_data\"\n",
    "currootdir = os.getcwd() +\"/\" + ssidatapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSI_data_2021-11-01\n",
      "2021-11-01\n"
     ]
    }
   ],
   "source": [
    "prevDownloads = os.listdir(currootdir)\n",
    "mostRecent = prevDownloads[-1]\n",
    "print(mostRecent)\n",
    "# curDate = np.datetime64(mostRecent[-2:] + '-' + mostRecent[-5:-3] + '-' + mostRecent[-10:-6])\n",
    "mostRecentDate = np.datetime64(mostRecent[-10:])\n",
    "mostRecentDate \n",
    "print(mostRecentDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostRecentDate = np.datetime64('2021-08-11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT NOT YET FINISHED!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overv√•gningsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a file; continues...\n",
      "not a file; continues...\n",
      "2021-11-02\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "2021 not found in link; continues...\n",
      "not a file; continues...\n",
      "not a file; continues...\n",
      "not a file; continues...\n"
     ]
    }
   ],
   "source": [
    "get_data = True\n",
    "ssidatapath = \"ssi_data\"\n",
    "rootdir = os.getcwd() +\"/\" + ssidatapath\n",
    "\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "url = \"https://covid19.ssi.dk/overvagningsdata/download-fil-med-overvaagningdata\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "links = soup.find_all(\"a\", string=lambda text: \"data\" in str(text).lower())\n",
    "\n",
    "check_str = \"<a href=\\\"https://files.ssi\"\n",
    "for link in links[3:]: \n",
    "    # print('---')\n",
    "    #print(link)\n",
    "    if str(link)[:len(check_str)]!=check_str:\n",
    "        print(\"not a file; continues...\")\n",
    "        continue\n",
    "    # print(link)\n",
    "    file = link[\"href\"]\n",
    "    yearPos = file.find('2021')\n",
    "    \n",
    "    if yearPos == -1:\n",
    "        print(\"2021 not found in link; continues...\")\n",
    "        continue\n",
    "\n",
    "    curDate = file[yearPos:yearPos+4] + '-' + file[yearPos-2:yearPos] + '-' + file[yearPos-4:yearPos-2] \n",
    "    \n",
    "    # print(file)\n",
    "    \n",
    "    # Only download new data\n",
    "    curDatetime = np.datetime64(curDate)\n",
    "    if (curDatetime > mostRecentDate):\n",
    "        print(curDatetime)\n",
    "\n",
    "        filename = \"SSI_data_\" + curDate\n",
    "        zipped_save_path = ssidatapath + \"_zipped/\" + filename + \".zip\"\n",
    "        extracted_save_path = ssidatapath + \"/\" + filename\n",
    "\n",
    "        \n",
    "        try:\n",
    "            download_url(file, zipped_save_path)\n",
    "            with zipfile.ZipFile(zipped_save_path, 'r') as zipObj:\n",
    "                zipObj.extractall(extracted_save_path)\n",
    "        except: \n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaccinedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a file; continues...\n",
      "not a file; continues...\n",
      "2021-11-02\n",
      "not a file; continues...\n",
      "not a file; continues...\n",
      "not a file; continues...\n"
     ]
    }
   ],
   "source": [
    "get_data = True\n",
    "ssivaccpath = \"ssi_vacc\"\n",
    "rootdir = os.getcwd() +\"/\" + ssivaccpath\n",
    "\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "# def get_all_data():\n",
    "url = \"https://covid19.ssi.dk/overvagningsdata/download-fil-med-vaccinationsdata\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "links = soup.find_all(\"a\", string=lambda text: \"data\" in str(text).lower())\n",
    "# print(links)\n",
    "check_str = \"<a href=\\\"https://files.ssi\"\n",
    "for link in links[3:]: \n",
    "    # print('---')\n",
    "    #print(link)\n",
    "    if str(link)[:len(check_str)]!=check_str:\n",
    "        print(\"not a file; continues...\")\n",
    "        continue\n",
    "    # print(link)\n",
    "    file = link[\"href\"]\n",
    "    yearPos = file.find('2021')\n",
    "    \n",
    "    if yearPos == -1:\n",
    "        print(\"2021 not found in link; continues...\")\n",
    "        continue\n",
    "    # print(yearPos)\n",
    "    # print(file[yearPos-4:yearPos+4])\n",
    "    curDate = file[yearPos:yearPos+4] + '-' + file[yearPos-2:yearPos] + '-' + file[yearPos-4:yearPos-2] \n",
    "\n",
    "\n",
    "    # Only download new data\n",
    "    curDatetime = np.datetime64(curDate)\n",
    "    if (curDatetime > mostRecentDate):\n",
    "        print(curDatetime)\n",
    "\n",
    "\n",
    "        filename = \"SSI_vacc_\" + curDate\n",
    "        zipped_save_path = ssivaccpath + \"_zipped/\" + filename + \".zip\"\n",
    "        extracted_save_path = ssivaccpath + \"/\" + filename\n",
    "        \n",
    "        try:\n",
    "            download_url(file, zipped_save_path)\n",
    "            with zipfile.ZipFile(zipped_save_path, 'r') as zipObj:\n",
    "                zipObj.extractall(extracted_save_path)\n",
    "        except: \n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-02\n"
     ]
    }
   ],
   "source": [
    "get_data = True\n",
    "ssidashpath = \"ssi_dashboard\"\n",
    "rootdir = os.getcwd() +\"/\" + ssidashpath\n",
    "\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "url = \"https://covid19.ssi.dk/overvagningsdata/download-fil-med-overvaagningdata\"\n",
    "\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "# links = soup.find_all(\"a\", string=lambda text: \"data\" in str(text).lower())\n",
    "links = soup.find_all(\"a\", string=lambda text: \"dash\" in str(text).lower())\n",
    "check_str = \"<a href=\\\"https://files.ssi\"\n",
    "for link in links[1:]: \n",
    "    \n",
    "\n",
    "    if str(link)[:len(check_str)]!=check_str:\n",
    "        print(\"not a file; continues...\")\n",
    "        continue\n",
    "    file = link[\"href\"]\n",
    "    yearPos = file.find('2021')\n",
    "    \n",
    "    if yearPos == -1:\n",
    "        print(\"2021 not found in link; continues...\")\n",
    "        continue\n",
    "    # print(yearPos)\n",
    "    # print(file[yearPos-4:yearPos+4])\n",
    "    curDate = file[yearPos:yearPos+4] + '-' + file[yearPos-2:yearPos] + '-' + file[yearPos-4:yearPos-2] \n",
    "\n",
    "    # Only download new data\n",
    "    curDatetime = np.datetime64(curDate)\n",
    "    if (curDatetime > mostRecentDate):\n",
    "        print(curDatetime)\n",
    "\n",
    "        filename = \"SSI_dashboard_\" + curDate\n",
    "        zipped_save_path = ssidashpath + \"_zipped/\" + filename + \".zip\"\n",
    "        extracted_save_path = ssidashpath + \"/\" + filename\n",
    "        \n",
    "        try:\n",
    "            download_url(file, zipped_save_path)\n",
    "            with zipfile.ZipFile(zipped_save_path, 'r') as zipObj:\n",
    "                zipObj.extractall(extracted_save_path)\n",
    "        except: \n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Unknown string format: a/ssi_data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\main\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object)\u001b[0m\n\u001b[0;32m   2084\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2085\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2086\u001b[0m             \u001b[1;31m# If tzaware, these values represent unix timestamps, so we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d950cfe40111>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mlatestdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlatestDate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatestdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\main\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\main\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[0mutc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"utc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[0;32m    466\u001b[0m             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m             \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\main\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object)\u001b[0m\n\u001b[0;32m   2088\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2089\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2090\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2092\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\main\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object)\u001b[0m\n\u001b[0;32m   2073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2074\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2075\u001b[1;33m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[0;32m   2076\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2077\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\main\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\main\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mParserError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown string format: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Unknown string format: a/ssi_data"
     ]
    }
   ],
   "source": [
    "ssidatapath = \"ssi_data\"\n",
    "rootdir = os.getcwd() +\"/\" + ssidatapath\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    if not len(files) == 0:\n",
    "        latestdir = subdir\n",
    "        latestDate = pd.to_datetime(subdir[-10:])\n",
    "\n",
    "print(latestdir)\n",
    "print(latestDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c72cdf52cb3d31f207bca538e9396da8706c0ecf4a3038fb1c2b317934170431"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('main': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
